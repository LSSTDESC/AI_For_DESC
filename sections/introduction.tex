\newpage
\section{Introduction}

The Vera C. Rubin Observatoryâ€™s Legacy Survey of Space and Time (LSST) will produce unprecedented volumes of heterogeneous data (images, catalogs, alerts) that challenge traditional pipelines. The mission of the LSST Dark Energy Science Collaboration (DESC) is to convert these data into robust constraints on the dark sector by jointly measuring the cosmic expansion history and the growth of structure, thereby constraining the dark-energy equation of state, testing gravity on cosmological scales, probing dark matter, and informing parameters such as spatial curvature and the sum of neutrino masses. Delivering on these objectives requires methods that are statistically powerful, scalable, and operationally reliable. Recent advances in AI/ML have great promise for crucial roles in the analysis of the data, but still need to meet those stringent requirements to be truly useful. Here, by machine learning (ML) we refer to data-driven models that learn mappings between variables (e.g., photometry to redshift, galaxy fields to cosmological parameters) and can be deployed at multiple stages of analysis. Their scientific utility, however, hinges on trustworthy uncertainty quantification and reproducible integration within DESC workflows; without these elements, ML methods cannot meet the stringent requirements of cosmological inference. In parallel, we use artificial intelligence (AI) to denote large language models and agentic systems that can orchestrate tools and code, potentially reshaping workflows (e.g., literature triage, code generation, autonomous execution of complex analyses). As with ML, turning recent AI advances into reliable accelerators of discovery remains an open problem that requires careful evaluation and governance.

The strategic question for DESC is therefore how to develop and integrate AI/ML \textit{the right way}, so that these approaches become dependable components of LSST-era analyses. Intrinsically, this question is relevant for a broad range of scientific endeavors and collaborations, but DESC is uniquely positioned to pioneer robust AI/ML practices for fundamental physics as an international collaboration working with community-accessible data, with a strong open-source culture, and pursuing extremely demanding scientific objectives. This white paper surveys current capabilities and future opportunities for AI/ML across DESC and outlines the methodological and infrastructure requirements needed for their successful, reliable deployment.


This paper is organized to progress from science use-cases throughout DESC which already leverage AI/ML advances (\autoref{sec3:use_case_for_aiml}), to methodology improvements required for established ML techniques to meet the stringent requirements for DESC (\autoref{sec4:aiml_research}), to discussing emergent AI/ML methodologies that are on the cusp of profoundly affecting how analyses are conducted (\autoref{sec5:emerging_tech}). We also detail in (\autoref{sec6:infra_requirements}) the infrastructure and support requirements to facilitate the transition towards AI/ML operationalization, and we discuss in (\autoref{sec7:broader_coordination}) opportunities for broader coordination with external actors to further accelerate AI/ML progress for DESC science. 