\newpage
\section{Introduction}

The Vera C. Rubin Observatory's \acrshort{lsst} will produce unprecedented volumes of heterogeneous data (images, catalogs, alerts) whose full scientific exploitation demands continued methodological innovation. The mission of the \acrshort{desc} is to convert these data into robust constraints on the dark sector by jointly measuring the cosmic expansion history and the growth of structure, thereby shedding much-needed light on dark energy, dark matter, and possible deviations from general relativity. Delivering on these objectives requires methods that are statistically powerful, scalable, and operationally reliable. Recent advances in \acrshort{ai} and \acrshort{ml} show great promise for critical data analysis roles but still need to meet stringent requirements to be truly useful. \acrlong{ai} (\acrshort{ai}) refers broadly to systems capable of performing tasks that typically require human intelligence, including reasoning, perception, learning, and decision-making. \acrlong{ml} (\acrshort{ml}) is a subfield of AI in which algorithms learn patterns and relationships from data to make predictions or decisions, encompassing both classical methods (e.g., random forests, Gaussian processes) and deep learning (multi-layer neural networks). In the DESC context, ML methods learn mappings between variables (e.g., photometry to redshift, galaxy fields to cosmological parameters) and can be deployed at multiple stages of analysis. Their scientific utility, however, hinges on trustworthy uncertainty quantification and reproducible integration within DESC workflows; without these elements, ML methods cannot meet the stringent requirements of cosmological inference. In parallel, we use AI to denote systems capable of complex cognitive tasks---such as reasoning, knowledge synthesis, and natural language understanding---that can potentially orchestrate tools, generate code, and reshape scientific workflows. As with ML, turning recent AI advances into reliable accelerators of discovery remains an open problem that requires careful evaluation and governance.

The strategic question for DESC is therefore how to develop and integrate AI/ML \textit{the right way}, so that these approaches become dependable components of LSST-era analyses. Intrinsically, this question is relevant to a broad range of scientific endeavors and collaborations. Still, DESC is well positioned to pioneer robust AI/ML practices for fundamental physics as an international collaboration that works with community-accessible data, has a strong open-source culture, and pursues extremely demanding scientific objectives. In this white paper, we set out a strategic framework for how DESC should organize its AI/ML efforts, prioritize methodological investments, and respond effectively to new opportunities arising from rapid AI/ML progress. This paper is structured around four interconnected perspectives on AI/ML within DESC, each building on the previous to articulate a comprehensive strategy:

\paragraph{\autoref{sec3:use_case_for_aiml}: The Current Landscape: ML Across DESC Science} Machine learning is not a future aspiration for DESC: it is already deeply embedded in current science workflows. Here, we survey how ML methodologies intersect with DESC's primary cosmological probes: strong and weak gravitational lensing, galaxy clusters, \acrfull{snia} cosmology, large-scale structure, as well as cross-cutting analysis components including simulations, theory and modeling, deblending, \acrfull{photoz} estimation, and shape measurement. This inventory reveals a striking pattern: the same core methodologies (e.g. simulation based inference, differentiable programming, deep learning) appear repeatedly across disparate science cases, while the same fundamental challenges (e.g. uncertainty quantification, robustness to covariate shift and to model misspecification) represent concrete challenges across multiple working groups (see \autoref{fig:chord-diagram}).


\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/chord-diagram}
    \caption{Transversal connections between DESC science applications (left), AI/ML methodologies (top), and shared challenges (right), as surfaced by \autoref{sec3:use_case_for_aiml}. The recurring appearance of the same methods and challenges across disparate science cases motivates collaboration-wide coordination of AI/ML efforts rather than siloed development within individual working groups. An interactive version of this diagram is available at \url{https://codepen.io/EiffL/full/ByKxMaa}}
    \label{fig:chord-diagram}
\end{figure}


\paragraph{\autoref{sec4:aiml_research}: Lifting the Limits of ML: Methodological Research Priorities} Building on the challenges surfaced in Section~3, we identify the key methodological research axes where targeted investment can lift current limitations and enable ML methods to meet the precision and reliability standards demanded by LSST-era cosmology. We organize these priorities around several interconnected themes:
\begin{itemize}
    \item \textbf{Bayesian inference and \acrfull{acr:uq}:} Developing fast and scalable inference techniques that may unlock promising high-dimensional hierarchical models. Improving methods for reliably estimating uncertainty arising from limited training data and model limitations.
    \item \textbf{\Acrfull{acr:sbi} and model misspecification:} Advancing \acrfull{nde} techniques, optimal summarization methods, and diagnostics for detecting and mitigating the biases introduced when training simulations imperfectly represent real observations or when training datasets fail to capture the full diversity of LSST data.
    \item \textbf{Physics-informed approaches:} Hybridizing explicit physical models with flexible generative components (flows, diffusion models) and advancing differentiable programming frameworks that embed cosmological theory directly into ML architectures, ensuring that learned components remain interpretable, physically consistent, and robust to extrapolation.
    \item \textbf{Novelty detection and discovery:} Developing representation learning and active human--AI collaboration frameworks capable of identifying rare, previously unmodeled phenomena in LSST's vast data volumes.
\end{itemize}
These research directions are not purely academic exercises; they directly address the technical barriers that limit the deployment of ML at scale for DESC's most ambitious analyses. We articulate not only what needs to be developed, but why these specific advances matter for cosmological inference and how DESC can contribute to the broader AI research ecosystem by presenting demanding, scientifically motivated benchmarks.

\paragraph{\autoref{sec5:emerging_tech}: Looking Forward: Foundation models and Agentic AI}
While Sections~3 and~4 focus on current ML applications and their refinement, Section~5 adopts a forward-looking perspective, examining how two emerging AI paradigms (\textit{data foundation models} and \textit{LLM-based agentic systems}) have the potential to reshape large sections of DESC workflows in ways that go qualitatively beyond incremental improvements to existing methods.
\begin{itemize}
    \item \textbf{\Acrfullpl{fm}}, trained at scale on heterogeneous data modalities (images, spectra, time series, catalogs), offer the promise of \textit{reusable representations} that can be rapidly fine-tuned or directly deployed across a wide range of downstream tasks (classification, regression, anomaly detection, simulation-based inference) without retraining from scratch for each application. For DESC, this paradigm shift could enable unified, survey-scale feature extractors that serve as common backbones for weak lensing, photometric redshifts, transient classification, and more, dramatically reducing duplication of effort while ensuring cross-probe consistency. However, realizing this vision requires careful attention to uncertainty propagation, robustness to distribution shifts, architectural choices suited to astronomical data, and rigorous, community-governed benchmarking to ensure that foundation models meet DESC's validation standards.

    \item \textbf{LLM-driven agentic systems} are rapidly evolving from research prototypes into tools capable of orchestrating complex scientific workflows: querying databases, generating and executing code, synthesizing literature, and autonomously iterating on analyses. These systems offer tantalizing possibilities for accelerating exploratory research, onboarding new collaboration members, and scaling human oversight across large analysis campaigns. Yet they also introduce new risks: biased recommendations, irreproducible results, and erosion of scientific understanding if deployed without governance. Section~5 outlines both the transformative potential and the implementation requirements (provenance tracking, human-in-the-loop validation, benchmark design, and clear policies on data rights and model transparency) necessary to integrate agentic AI into DESC in ways that guarantee scientific rigor.
\end{itemize}
The forward-looking stance of Section~5 is deliberate: DESC must not only respond to today's ML methods but actively shape the trajectory of emerging AI technologies by setting clear scientific requirements, contributing demanding use cases to the broader AI research community, and pioneering governance frameworks that other collaborations can learn from.

\paragraph{\autoref{sec6:infra_requirements}, \ref{sec7:broader_coordination}, \ref{sec:aiml_risks}: Operationalizing AI/ML: Infrastructure, Coordination, and Risk Management}
Even the most sophisticated AI/ML methods will have limited impact if they cannot be reliably deployed, maintained, and integrated into DESC's production pipelines. The final sections of this white paper address the operational foundations required to translate research prototypes into dependable cosmological infrastructure. Section~6 details the \textit{infrastructure requirements} across software, computing, and data:
\begin{itemize}
    \item \textbf{Software:} Establishing a robust, collaboration-endorsed AI software stack (frameworks, experiment tracking, model registries, continuous integration/continuous deployment for models) that ensures reproducibility, portability across DESC computing facilities, and long-term sustainability over the LSST decade. This includes strategies for integrating AI components into DESC analysis pipelines and for managing the rapidly evolving ecosystem of LLMs and agentic frameworks.
    \item \textbf{Computing:} Securing the \acrfull{gpu} allocations, distributed training capabilities, and co-located data access necessary for foundation model development, large-scale simulation-based inference campaigns, and real-time alert stream processing. This involves strategic coordination with national labs such as the \acrfull{alcf} and \acrfull{olcf}, emerging initiatives (\acrshort{amsc}, \acrshortpl{hpdf}), and international partners (\acrshort{eurohpc}, \acrshortpl{idac}).
    \item \textbf{Data:} Ensuring that LSST data products, multi-survey training datasets, and simulation outputs are accessible, well-documented, and equipped with the interfaces---e.g., \acrfullpl{api}, streaming services, tokenization strategies---required for efficient AI/ML workflows. This includes establishing shared repositories, benchmark datasets, and provenance standards.
\end{itemize}

Section~7 broadens the scope to examine \textit{opportunities for coordination beyond DESC}: with the other Rubin LSST Science Collaborations, Stage-IV experiments (in particular \acrshort{desi}, \acrshort{4most}, Roman, Euclid), AI institutes (e.g., NSF--Simons institutes, CosmicAI), European networks (e.g., \acrshort{eucaif}, \acrshort{ellis}), and the Rubin alert broker ecosystem. These partnerships offer opportunities for shared training data, cross-survey foundation models, joint benchmark development, and access to specialized compute resources and expertise. DESC is uniquely positioned to act as both a consumer and a driver of AI methodologies within this broader ecosystem, articulating the demanding requirements of precision cosmology while contributing validated methods and datasets that benefit the wider community.

Finally, Section~8 confronts the \textit{risks and challenges} inherent in DESC's increasing reliance on AI/ML: model miscalibration, opaque failure modes, reproducibility challenges, data governance complexities, and the potential erosion of human scientific understanding. We outline concrete mitigation strategies (validation protocols, redundancy in critical analyses, provenance tracking, training programs, and governance structures) that apply the same rigor to AI components as to any other element of the cosmological inference pipeline.


\paragraph{\autoref{sec:conclusion}: Conclusion} Viewed as a whole, this paper shows that AI/ML is already central to DESC science (\autoref{sec3:use_case_for_aiml}), but unlocking its full potential requires targeted methodological research (\autoref{sec4:aiml_research}), proactive engagement with emerging technologies (\autoref{sec5:emerging_tech}), and robust operational foundations (\autoref{sec6:infra_requirements}--\ref{sec:aiml_risks}). The transversality of methods and challenges across DESC working groups demands deliberate coordination to prevent fragmented effort and ensure that best practices, validated tools, and lessons learned propagate rapidly throughout the collaboration. By articulating this vision (grounded in current capabilities, guided by research priorities, forward-looking in its engagement with foundation models and agentic AI, and operationally realistic about infrastructure and risk) DESC can position itself not only to meet its own science goals but to pioneer robust AI/ML practices for fundamental physics that serve as a model for the broader community. 
