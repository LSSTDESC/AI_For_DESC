\newpage
\section{Executive Summary}

This executive summary distills the key recommendations, opportunities, and strategic takeaways emerging from this document that can help inform a coherent AI/ML strategy for DESC. We start by establishing below the \textbf{core driving principles} that guide our strategic thinking:
\begin{itemize}
    \item \textbf{Facilitating the delivery of DESC science} through the integration of AI/ML tools, while \textbf{fulfilling the stringent requirements} of precision cosmology.

    \item Building and maintaining a \textbf{sustainable AI/ML ecosystem} required for the collaborative development, validation, and deployment \textbf{of production-grade AI/ML tools}.

    \item Seeking out opportunities to leverage \textbf{DESC’s unique position} as a large international collaboration using community-accessible data, and pursuing extremely demanding scientific objectives, to \textbf{establish DESC as a pioneer in the development of robust AI/ML practices for fundamental physics}.

    \item Integrating AI/ML into DESC in ways that \textbf{preserve and amplify the human-centric nature of research}, strengthen collaboration quality, and \textbf{keep contributors’ work at the center}.
\end{itemize}


\paragraph{Organizational Structure \& Governance} Effective integration of AI/ML across DESC requires coordination mechanisms and clear standards. 

\begin{itemize}
  \item \textbf{R1: Develop DESC-wide AI/ML Coordination Mechanisms.} Establish structures (standing working group, cross-WG task forces, regular interchange meetings) to share methodological innovations across probes, tackle common challenges collectively, and minimize duplication. Facilitate rapid dissemination through workshops, tutorials, and methodological discussions. (\autoref{sec3:use_case_for_aiml})

  \item \textbf{R2: Codify AI/ML best practices.} Extend Publication Policy with an AI/ML checklist, establish a standard of full reproducibility and provenance tracking for AI/ML results, standardize validation checks for ML methods (coverage tests, PIT histograms, distribution-shift diagnostics, stress tests under deliberate misspecification.) Cross-working group deliverables that use machine learning, such as foundation models and simulations, should be supported by comprehensive benchmarks that are solicited from DESC members and represent a broad array of science cases. (\autoref{sec3:use_case_for_aiml}, 
  \autoref{sec4:aiml_research}, \autoref{sec5:emerging_tech})
\end{itemize}

\paragraph{Advancing Key Methodological Research Directions} Several foundational ML challenges recur across DESC science cases and merit dedicated investment.
\begin{itemize}
    \item \textbf{R4: Invest in Foundational Methodological Research.}  Prioritize and facilitate shared research in several critical areas: uncertainty quantification, simulation-based inference robustness, physics-informed modeling (hybrid generative-physical architectures), validation of neural posteriors, and novelty detection. Progress on these foundational challenges will have an outsized impact across many DESC science cases. (\autoref{sec3:use_case_for_aiml}, \autoref{sec4:aiml_research})

    \item \textbf{O1: Methodological Leadership as Strategic Opportunity.} The challenges DESC faces (robust inference under misspecification, calibrated UQ at scale, physics-informed learning) are frontier problems in machine learning broadly, creating natural opportunities to attract CS/ML collaborators and position DESC as a leader in trustworthy AI for fundamental science. (\autoref{sec4:aiml_research}, \autoref{sec7:broader_coordination})
    
    \item \textbf{O2: Leverage DESC Simulation Assets as Community Benchmarks.} DESC's combination of petabyte-scale community data, stringent scientific requirements, and rich simulation assets (PLAsTiCC, ELAsTiCC, CosmoDC2) makes it an ideal testbed for pioneering robust AI/ML practices. Benchmarks and governance standards developed here can become reference implementations for fundamental physics, while attracting CS/ML collaborators who see DESC's frontier challenges as compelling research problems. (\autoref{sec3:use_case_for_aiml}, \autoref{sec4:aiml_research}, \autoref{sec7:broader_coordination})
\end{itemize}


\paragraph{Foundation Models} Large-scale foundation models are transforming AI capabilities, and DESC must develop both the infrastructure to deploy them and the benchmarks to validate them for precision cosmology.
\begin{itemize}

\item \textbf{R5: Invest in Shared Foundation Model Infrastructure.} Develop a shared foundation model backbone for DESC, consistent across data modalities, of production-grade quality, and served behind stable APIs. (\autoref{sec5:emerging_tech}, \autoref{sec6:infra_requirements})

\item \textbf{R6: Establish DESC-specific Foundation Models Validation Standards.} Create benchmarks that go beyond industry practice: uncertainty calibration, robustness to systematics, sensitivity to training biases, stress tests under distribution shift (temporal, spatial, cross-survey). 
Develop astronomy-specific interpretability tools to verify physically meaningful representations. (\autoref{sec5:emerging_tech}, \autoref{sec:aiml_risks})

\item \textbf{O3: Lead Rubin-wide Development of Foundation Models.} DESC can play a central role in coordinating foundation model development across Rubin Science Collaborations, AI institutes (SkAI, CosmicAI, IAIFI), and LINCC Frameworks, pursuing a distributed approach that prototypes at universities, scales pre-training on EuroHPC/DOE facilities, and fine-tunes near the data on DESC systems. (\autoref{sec5:emerging_tech}, \autoref{sec7:broader_coordination})
\end{itemize}

\paragraph{LLMs \& Agentic AI} LLMs and agentic AI present opportunities to accelerate research and lower barriers to complex analyses, but their integration requires deliberate governance and validation frameworks.

\begin{itemize}

  \item \textbf{R7: Establish Governance for LLMs and Agentic Systems.} Coordinate DESC-wide 
  activities involving LLMs and agents, establish best practices including evaluation, review, and red-teaming of pilot studies. Include critical discussions of the technology's limits and effects on human researchers, involving experts across domains. Engage with LSST Data Management to ensure agentic AI can interface with data products effectively and reliably. (\autoref{sec5:emerging_tech}, \autoref{sec:aiml_risks})

  \item \textbf{R8: Build Natural Language Interfaces to DESC Resources.} Develop RAG-based interfaces to DESC documentation, simulations, and data products, lowering onboarding barriers and democratizing access to complex pipelines. (\autoref{sec5:emerging_tech}, 
  \autoref{sec6:infra_requirements})

  \item \textbf{O4: Pioneer Agentic AI for Scientific Rigor and Reproducibility.} Develop 
  "DESC research agents" that automate execution, documentation, and validation of analyses 
  against standardized benchmarks, coupling these systems to clear governance and red-teaming procedures so that agentic workflows enhance transparency, provenance, and trust in DESCresults. (\autoref{sec5:emerging_tech}, \autoref{sec:aiml_risks})
\end{itemize}


\paragraph{Infrastructure \& Software} Strategic infrastructure investments (in software stacks, differentiable libraries, and data interfaces) act as multipliers that benefit all DESC science cases.
\begin{itemize}
  \item \textbf{R9: Establish a Durable AI Software Stack.} Adopt a coherent set of frameworks (PyTorch for large models, JAX for differentiable physics), tooling (experiment tracking, model registries, CI/CD), and export standards (ONNX). The stack should be portable across NERSC and CC-IN2P3, sustainable over the 10-year survey, and prioritizing open governance to avoid proprietary lock-in. (\autoref{sec6:infra_requirements})

  \item \textbf{O5: Differentiable Programming as Technical Multiplier.} Investment in the JAX-based differentiable programming ecosystem acts as a multiplier, simultaneously enabling gradient-based sampling, GPU acceleration, hybrid physics-ML models, and end-to-end optimization across DESC pipelines. (\autoref{sec3:use_case_for_aiml}, \autoref{sec4:aiml_research}, \autoref{sec6:infra_requirements})

\item \textbf{O6: Leverage Emerging AI Computing Infrastructure.} Significant new AI-oriented 
computing is becoming available: DOE infrastructure (American Science Cloud, HPDF), the IDAC 
network (UK Full IDAC with ASCEND), and EuroHPC systems (Leonardo, LUMI, JUPITER exascale). 
DESC should engage early to shape these resources for cosmology and secure allocations for 
foundation model training at scales infeasible on current systems. 
(\autoref{sec6:infra_requirements}, \autoref{sec7:broader_coordination})
\end{itemize}

\paragraph{External Coordination \& Partnerships} DESC operates within a rich ecosystem of surveys, AI institutes, and computing partners: deliberate coordination amplifies impact and avoids duplicated effort.
\begin{itemize}
  \item \textbf{R10: Coordinate with Rubin Science Collaborations.} Partner deliberately with 
  ISSC for methodological development, TVS for time-series and broker stress-testing, Galaxies 
  for deblending/morphology benchmarks. Encourage sharing tools and best practices. (\autoref{sec7:broader_coordination})

  \item \textbf{R11: Engage with AI Institutes and Networks.} NSF-Simons AI Institutes 
  (\$60M, explicit LSST/cosmology themes) and European networks (e.g. EuCAIF) are natural partners. 
  Build systematic engagement through co-funded postdocs, shared workshops, joint proposals, 
  and benchmark datasets. These efforts would connect DESC to the broader AI-for-science ecosystem. 
  (\autoref{sec7:broader_coordination})

    \item \textbf{R12: Developing the human-machine interface.} Close connections should be developed between DESC, other LSST science collaborations, in-kind follow-up programmes, alert broker teams, LSST data management and citizen scientists, to facilitate active learning for classification and anomaly detection. (\autoref{sec4:aiml_research}, \autoref{sec7:broader_coordination})

  \item \textbf{O7: Leverage DESC's Broker Ecosystem Presence.} DESC members are embedded in 
  all seven Rubin Community Brokers—tight coordination gives direct leverage over SN Ia sample 
  purity, selection effects, and host-galaxy priors, plus an on-ramp from research prototypes 
  to community-facing services. (\autoref{sec3:use_case_for_aiml}, \autoref{sec7:broader_coordination})
\end{itemize}

% \hline

% \paragraph{Key Opportunities and Recommendations} 

% \begin{itemize}

  % \item \textbf{R1: Develop DESC-wide AI/ML best practices.} Extend Publication Policy with an AI/ML checklist, consolidate a small set of supported AI/ML stacks, establish DESC-wide model registry with automated robustness tests, establish a standard of full reproducibility for AI/ML results. 

  % \item \textbf{R2: Establish governance for LLMs and agentic systems.} Coordinate DESC-wide activities involving LLM/agents, establish best practices and evaluation/review/red-teaming of pilot studies, include critical discussions of the limits of the technology and its effects on human researchers, involving experts in other domains. DESC should engage with the LSST Data Management team to allow developed agentic AI to interface with data products effectively and reliably.

  % \item \textbf{R3: Champion Differentiable Programming and Hybridization of Physical models with Generative Modeling.} Promote differentiable programming and hybrid physics-ML models that embed cosmological theory and simulators directly into AI architectures.

  % \item \textbf{R4: Build Strategic Methodological Partnerships in AI and Computer Science.} Establish long-term collaborations with computer science departments and AI institutes focused on the foundational challenges identified in this document (robust uncertainty quantification, model misspecification and covariate shift, validation of neural posteriors and generative models).

   % \item \textbf{Standardization and benchmarking.} Rigorous protocols for benchmarking, validation, domain adaptation, and uncertainty quantification must be established as standard practice for all DESC machine learning projects and outlined within AI/ML policy guidelines. Furthermore, cross-working group deliverables that use machine learning, such as foundation models and simulations, should be supported by comprehensive benchmarks that are solicited from DESC members and represent a broad array of science cases.
% \item \textbf{Developing the human-machine interface.} Close connections should be developed between DESC, other LSST science collaborations, in-kind follow-up programmes, alert broker teams, LSST data management and citizen scientists, to facilitate active learning for classification and anomaly detection.
% \item \textbf{Compute and workforce needs.} Investment in computational infrastructure and specialized technical expertise must be secured to keep pace with the escalating demand for AI research and deployment within DESC.

  % \item \textbf{O1: Lead Rubin-wide Development of Foundation Models.} DESC can play a key role in coordinating various actors, ranging from other Rubin LSST Science Collaborations to a wide range of academic institutions and AI institutes, on the development of frontier AI models for the Rubin Community.

  % \item \textbf{O2: Pioneer Agentic AI for Scientific Rigor and Reproducibility.} Develop “DESC research agents” that automate the execution, documentation, and validation of analyses against standardized DESC benchmarks, coupling these systems to clear governance and red-teaming procedures so that agentic workflows enhance transparency, provenance, and trust in DESC results.

  % \item \textbf{O3: Establish DESC as a Hub for AI-for-Cosmology Training.} Create a sustained Rubin-focused AI/ML training program (schools, tutorials, and mentoring) built around DESC’s open-source software and challenging datasets, in partnership with leading AI institutes and industry, to train the next generation of researchers in trustworthy, physics-informed AI for cosmology.

 % \item \textbf{Strategic leadership in inference.} DESC should capitalize on its leadership position in simulation-based inference (SBI) and broader Bayesian methodologies, with a specific focus on mitigating model misspecification. To sustain this expertise, collaboration meetings and Dark Energy Schools should be leveraged for knowledge transfer between research groups.
% \end{itemize}