\newpage
\section{Emerging Techniques}
\label{sec5:emerging_tech}
The priorities outlined in \autoref{sec4:aiml_research} establish the statistical and algorithmic foundations for \acrshort{ml}-enabled cosmology, but realizing these priorities at the scale and complexity of \acrshort{lsst} demands new approaches. Training distinct models for each science case is neither computationally sustainable nor conducive to the cross-probe consistency required for joint analyses. 

This section surveys two classes of emerging \acrshort{ai} techniques that may fundamentally change how \acrshort{desc} builds and maintains its analysis infrastructure: data \acrshortpl{fm} (\autoref{sec:foundation_models}) and \acrshort{llm}-based agentic systems (\autoref{sec:llm_agentic}). By building general-purpose and reusable models from large unlabeled datasets, data FMs offer the potential for a shared backbone ML infrastructure that can be applied across science cases, greatly reducing time to science for analyses involving ML. LLMs and \acrfullpl{mas} target a different bottleneck: the coordination of complex workflows, synthesis of documentation and literature, and accessibility of the DESC software infrastructure to new collaboration members. Together, these techniques provide a framework for scaling the ML efforts in DESC from individual analyses to reproducible, collaboration-wide pipelines.

\subsection{Data Foundation Models}
\label{sec:foundation_models}
% \coordinator{Michelle Lochner}
% General intro FMs
% Motivation for FM for DESC
%    - Pre-training and reusability
%    - Opportunities offered by multimodality
% Technical considerations
%    - Neural Architectures 
%    - Training objectives 
% Evaluation 

\acrshortpl{fm}, \acrshort{ai} systems trained on massive datasets to perform a broad spectrum of tasks \citep{Bommasani2021FoundationModels}, have not only revolutionized AI research but are also rapidly reshaping modern life. Vision FMs are now enabling breakthroughs in robotics \citep{RobotApplication2024}, medical diagnostics \citep{MedicalApplication2024}, and remote sensing \citep{RemoteSensing2024}. Beyond these applications, their adoption in scientific disciplines such as genetics \citep{Evo2025} and heliophysics \citep{Surya2025} has highlighted their powerful predictive capabilities and their capacity to uncover fundamental relationships in complex data. The burgeoning field of FMs presents a significant opportunity to enable and accelerate cutting-edge astrophysics.

Zoobot \citep{Zoobot2022} can be considered the first vision FM in optical astronomy. Having been trained on labels from the Galaxy Zoo citizen science project \citep{GalaxyZoo2008, GalaxyZoo2011, GalaxyZoo2013}, it has demonstrated versatility on a range of downstream tasks. These include broad morphological classification problems critical for studies of galaxy evolution, such as identifying merging galaxies \citep[e.g.,][]{MergersHSC2023,MergerChallenge2024, MergerSims2025}, and anomaly detection for finding rare phenomena like strong lenses \citep{walmsley25, lines25}. Formally released in \citet{ZoobotRelease2023}, Zoobot has been adapted to imaging data from multiple surveys, including \acrshort{desi} \citep{DECALS2019}, \textit{Euclid} \citep{ZoobotEuclid2024}, \acrshort{hst} \citep{ZoobotHST2023}, and \acrfull{jwst} simulations \citep{ZoobotJWST2024}, among others \citep{ZoobotGAMA2024, ZoobotUNIONS2025, ZoobotHSC2025}.

FMs have also been designed for astronomical time-series datasets, spurred by the need for automated photometric classification of Galactic and extragalactic transients in the Rubin era. Some examples of these models include Astromer \citep{Astromer2023, Astromer2025}, AstroCo \citep{Astroco2025}, ATAT \citep{ATAT2024}, FALCO \citep{FALCO2025}, and RoMaE \citep{ROMAE2025}. While the primary requirement for these models is high classification accuracy, they also enable the discovery of new classes of transients through anomaly detection, and, in some cases, provide lightcurve interpolation for further downstream analysis.

Despite early successes in modality-specific FMs, many astrophysical questions can only be answered by fusing different data types. This is a task for which traditional methods, which rely on reducing data to summary statistics, are quickly being outpaced by powerful multimodal FMs. Though the ideal neural architectures and training objectives for these multi-modal models are areas of active research, models have now been developed for galaxies \citep{Astroclip2024}, \acrshort{sne} \citep{2024Zhang_Maven}, variable and non-variable stars \citep{2024Leung_stellarfm,AstroM2025}, and cosmological simulations \citep{MOSAIC2025}. AION-1 \citep{parker2025aion} represents a significant step toward survey-scale multimodal FMs: trained on over 200 million observations of both stars and galaxies from five major surveys, it integrates images, spectra, and scalar measurements into a billion-parameter model. AION-1 demonstrates strong performance in low-data regimes, enables zero-shot detection of rare objects such as strong gravitational lenses, and produces survey-invariant representations that facilitate knowledge transfer across telescopes. 

\subsubsection{Foundation Models for DESC Science}
\paragraph{Pre-training and reusability} 
FMs offer a significant advantage over existing techniques by reducing heterogeneous data types into a unified and simplified numerical representation known as a latent space, representation or feature space. Instead of reprocessing a full dataset for each analysis, a single, powerful FM can generate rich data representations once. These representations can then be used directly or rapidly finetuned for numerous specific science cases, resulting in significant savings of computing resources. 

This shared representational basis also changes how \acrshort{desc} can approach cosmological inference. Traditional analyses reduce complex image data to limited summary statistics (e.g., moments, colors, or flux ratios), inevitably discarding information. Deep learning enables direct inference from raw observations, but training bespoke networks for each task across the petabyte-scale archive of \acrshort{lsst} is infeasible. A general-purpose FM, trained once at scale, can thus act as a reusable ``backbone'' for all DESC pipelines, propagating consistent representations across tasks. 

For time-domain astronomy, the representations produced by FMs are especially powerful. Because models learn features directly from the data, they are not constrained by the a priori assumptions of human-engineered features. This makes them ideal for identifying new or unexpected classes of objects via anomaly and novelty detection. Furthermore, these representations could be highly effective for standard tasks such as early transient classification, which is critical for triggering spectroscopic follow-up.

For simulation-based inference (\autoref{sec4:sbi}), FM latent spaces can act as highly flexible encoders, providing a more powerful data compression than traditional statistical summaries. In terms of data handling, multimodal models can naturally accommodate missing data when fusing datasets. Moreover, the ability to pre-train on vast unlabeled datasets enables FMs to address the representational bias (dataset shift) often encountered between the training and test sets in supervised learning.

\paragraph{Opportunities offered by multimodality}
 In astronomy, multi-wavelength models learn a shared latent space from multiple observational wavelengths (e.g., optical and infrared) of the same object. Multimodal models extend this concept by integrating fundamentally different data types into a shared latent space, often through self-supervised learning techniques. While the specific AI architectures for combining heterogeneous datasets remain in active development, all approaches fundamentally treat different data types as complementary views of the same underlying astrophysical system. The resulting multimodal representations provide a computationally efficient and powerful framework for a broad spectrum of scientific analyses.

In the time domain, joint modeling of photometric light curves and spectra provides a direct path to improving supernova cosmology and our understanding of explosion physics. A multimodal FM can perform cross-modal imputation, predicting the spectral properties of SNe Ia from irregular photometric sequences alone \citep[as has been demonstrated on synthetic data;][]{2025Shen_DitSNe,2025Shen_MMVAE}, thereby recovering physically meaningful features (line velocities or continuum temperatures) that are otherwise inaccessible from broadband imaging data. These inferred spectra can serve as additional standardization parameters for SNe Ia, potentially reducing residuals in the Hubble diagram by incorporating information linked to, e.g., progenitor diversity \citep{2025Son_AgeBias} or host metallicity \citep{2013Childress_Metallicity}.

Beyond improving standardization, the same cross-modal embeddings enable proactive discovery. By comparing inferred to obtained spectra, outliers can be flagged for long-term monitoring. When combined with host-galaxy properties across the transient samples discovered by Rubin LSST, these models can provide a probabilistic mapping between host galaxy and transient properties, useful for exploring population-level correlations potentially linked to supernova physics and for obtaining sub-populations of highly-standardizable SNe Ia.

\paragraph{Challenges}
Despite rapid progress, technical and practical challenges must be addressed before multimodal FMs can be fully integrated into DESC pipelines. Propagating observational uncertainties to all studies conducted downstream of a DESC-wide FM is critical, and the diversity of applications across spatial and temporal scales may not be well matched to a single architecture's inductive biases. Multiple application areas also require capturing the impact of selection effects in extant training samples, which may cause a model to over-weight well-observed populations and under-represent rare but scientifically informative objects. A related challenge is ensuring that learned embeddings disentangle instrumental systematics (e.g., tracking issues, bright sky backgrounds) from true astrophysical signal. Architectures that explicitly factorize instrumental and astrophysical contributions to observed data offer a promising avenue \citep[e.g.,][]{2025Audenaert_CausalFMs}, and further development of such approaches will be essential for meeting DESC's calibration requirements. 

\subsubsection{Training Objectives}
Training objectives determine whether FMs learn astrophysically meaningful structure or merely reproduce observational correlations. For DESC, these objectives must explicitly promote representations that encode physical invariants (e.g., morphology–redshift relations, color–temperature gradients) while remaining robust to the observational systematics and covariate shifts defined as calibratable in the Science Requirements Document. \Acrfull{ssl} offers the most practical and scalable route toward this goal, as it enables the extraction of representations from vast unlabeled datasets without compromising the requirement for bias quantification and calibration in DESC.

\paragraph{Self-supervised learning}
SSL encompasses a range of approaches: reconstructive methods, such as autoencoders \citep{Autoencoders1993, Autoencoders2006}, learn to compress data into a low-dimensional representation and then reconstruct the original input; contrastive learning \citep{Contrastive2020, NonContrastive2021} trains models to produce invariant representations for augmented versions of the same data point (e.g., zoomed or rotated); and predictive methods, often implemented via transformer architectures \citep{Transformers2017}, learn by predicting masked or omitted sections of data based on their surrounding context. The principal advantage of SSL is its scalability, allowing models to be trained on vast datasets without costly manual annotation. 

\paragraph{Generative approaches}
Beyond these paradigms, generative and diffusion-based models are also being adapted for self-supervised representation learning in the astronomical domain. Although originally designed for data synthesis, diffusion objectives \citep{2022Yang_Diffusion} can act as powerful denoisers and uncertainty estimators,  aligning with the DESC requirement that calibratable systematic errors remain subdominant to statistical uncertainties. How to manage a good generative model in the context of galaxy image synthesis has been investigated for instance using this denoising capability of score-based diffusion models \citep{Campagne_2025}. Hybrid diffusion autoencoders \citep{2021Preechakul_DiffAEs} combine reconstructive and generative losses, yielding latent spaces that capture astrophysical variation while marginalizing over observational noise. Methods such as these will be critical for DESC to achieve unbiased shear and photometric-redshift inference with Rubin data.

\paragraph{Unsupervised learning considerations}
As highlighted in \autoref{sec:discovery}, the vast LSST dataset will hold immense potential for scientific discoveries. Given this sheer scale, FMs will be critical for creating powerful representations that enable anomaly detection, unsupervised source classification, and similarity searches. However, a significant challenge remains: FMs are typically designed and optimized for supervised tasks, while their use for unsupervised applications is often an afterthought. Recent work by \citet{ZoobotApplications2022} and \citet{Protege2025} demonstrates this gap. They found that traditional anomaly detection methods fail when applied to the deep latent features learned by both supervised and self-supervised methods. This indicates a clear need for new research: new unsupervised methods compatible with these features must be developed \citep[such as \href{https://github.com/MichelleLochner/astronomaly}{\texttt{Astronomaly} \texttt{Protege}};][]{Protege2025} and FMs must be optimized specifically for unsupervised discovery.

\subsubsection{Architectural Innovations}
Realizing the capabilities of FMs for DESC science requires architectural and training advancements. Astronomical data presents unique barriers to large-scale training, including wide dynamic ranges from faint to bright objects, Poisson noise properties, multi-wavelength observations, and irregular sampling. These characteristics, combined with the science priorities of DESC, necessitate architectures that not only achieve optimal representational power on LSST data but also permit robust uncertainty propagation.

% \paragraph{Neural architectures}
%%Continuous neural fields (NeRFs, SIREN) offer a paradigm shift for representing astronomical observations as continuous functions rather than discrete pixels. For weak lensing, this could enable resolution-independent shape measurements by learning continuous representations of galaxy light profiles. DESC could leverage these architectures to naturally handle PSF convolution in function space rather than pixel space, potentially eliminating pixelization systematics entirely.

%State-space models (S4, Mamba) provide linear-time sequence modeling with unbounded context, ideal for LSST's decade-long light curves. In contrast to transformers’ quadratic attention cost, SSMs maintain long-range temporal memory while preserving physical interpretability via explicit time constants and impulse responses—critical for capturing slow-evolving variability or secular evolution across the full LSST survey baseline.

%%% Old version
% Efficient attention mechanisms have matured significantly beyond standard transformers toward architectures that can scale to LSST-level data volumes. Flash Attention and its variants reduce memory footprint by 10-100x through tiling and kernel fusion, making CCD- or raft-scale attention suddenly feasible. Sparse attention patterns (Longformer's sliding window + global tokens, BigBird's random + window + global) could naturally map to astronomical hierarchies, such as by imposing local attention for nearby galaxies and global tokens for cluster properties. These designs directly support DESC’s need to jointly model small- and large-scale correlations that may affect shear, clustering, and supernova systematics.

% Hierarchical Vision Transformers (e.g., Swin Transformer V2) represent an especially promising class for DESC imaging applications. Their multi-resolution attention windows mirror the multi-scale nature of cosmological information, from pixel-level PSF modeling to large-scale galaxy clustering. Such architectures could unify weak-lensing and large-scale-structure analyses under a shared image encoder, enabling end-to-end uncertainty propagation across spatial scales as a direct step toward DESC’s requirement for cross-probe consistency in systematic control.

% Finally, architectures supporting multimodal data fusion are essential for LSST-scale inference. Early-fusion models \citep[e.g., Chameleon][]{Chameleon2024} integrate multiple data types during training, while late-fusion approaches merge specialized encoders post hoc \citep{2023Pereira_LateFusion}. Architectures like the Perceiver family \citep{2021Jaegle_Perceiver,2021Jaegle_PerceiverIO} generalize these ideas further by learning compressed latent arrays that can flexibly accommodate new data modalities. This is an operational advantage for DESC, where evolving survey conditions and ancillary datasets (DESI, Roman, 4MOST/TiDES) demand continuous integration into the shared analysis space.

\paragraph{Attention}
Efficient attention mechanisms, which allow models to weigh the importance of different parts of the input data, have evolved significantly beyond standard transformers, offering new architectures that can scale to LSST-level data volumes. Methods like Flash Attention \citep{FlashAttention2022} use techniques such as tiling and kernel fusion to reduce the memory footprint by 10-–100$\times$. This significant reduction for the first time makes practical application of attention mechanisms at the scale of individual \acrfullpl{ccd} or rafts. 

\paragraph{Hierarchical Approaches}
Astronomical data is inherently hierarchical, with structures ranging from individual galaxies to massive clusters. Sparse attention models like Longformer \citep{Longformer2020} and BigBird \citep{BigBird2020} are well-suited to this, as their architecture directly mirrors this physical structure. They use local attention (e.g., sliding windows) to model interactions between nearby objects, while global tokens aggregate information about the entire system. These designs are critical for DESC, as they enable the joint modeling of small- and large-scale correlations essential for controlling systematics in shear, clustering, and supernova analyses. This hierarchical approach is well-developed in vision models, with hierarchical vision transformers \citep[e.g., Swin Transformer V2,][]{Swin2022} being especially promising for DESC imaging. Unlike the token patterns in sparse models, these architectures use multi-resolution attention windows that mirror the multi-scale nature of cosmological information, enabling pixel-level \acrshort{psf} modeling up to large-scale galaxy clustering. This design could enable the unification of weak lensing and large-scale structure analyses using a shared image encoder. Such a model would facilitate end-to-end uncertainty propagation across spatial scales, directly addressing the DESC requirement for cross-probe consistency in systematic control.

\paragraph{Mixture-of-Experts}
The principle of a shared, unifying backbone extends to \acrfull{moe} architectures, which offer natural alignment with DESC objectives. Rather than training independent networks for each object class or redshift regime, sparse MoE layers -- such as the Switch Transformer \citep{Switch2022} and Mixtral \citep{Mixtral2024} -- can dynamically route inputs through specialized sub-networks while preserving a common latent backbone. This paradigm mirrors the DESC software model itself: probe-specific inference modules built atop a common analysis infrastructure. E.g., expert sub-networks could specialize in quiescent versus star-forming galaxies or early- versus late-time transients, while shared latent features will ensure cross-consistency in calibration and selection functions across working groups.

\paragraph{Data Fusion}
A final architectural requirement is multimodal data fusion, driven by the operational need to combine LSST data with a continuous stream of ancillary datasets (e.g., \textit{Roman}, \acrshort{desi}, \acrshort{4most}/\acrshort{tides}) as well as managing evolving observing conditions. This challenge can be addressed with early-fusion models, which tokenize heterogeneous data types into a common representation space for joint training \citep[e.g., 4M, Chameleon;][]{4M2024,Chameleon2024}; AION-1 \citep{parker2025aion} exemplifies this approach in astronomy, using modality-specific tokenizers to convert images, spectra, and scalar measurements into discrete tokens before unified transformer-based masked modeling. Alternatively, late-fusion approaches merge specialized encoders post hoc \citep{2023Pereira_LateFusion}. More generalized architectures, like the Perceiver family \citep{2021Jaegle_Perceiver, 2021Jaegle_PerceiverIO}, are particularly advantageous. By learning a single, compressed latent array, they are explicitly designed to flexibly accommodate new data modalities. This provides a clear operational path for DESC to update and expand its shared analysis space continuously. For a comprehensive review of fusion strategies and their trade-offs in astronomical applications, see \citet{SHAO2026104103}.

Together, these architectural innovations suggest a coherent design philosophy for DESC FMs: hierarchical representations that preserve cosmological structure, modular routing across scientific workflows, and learned compression layers capable of cross-probe alignment. Each of these desiderata drive toward reproducible, uncertainty-aware analyses within a unified DESC software framework.



\subsubsection{Evaluation}
In contrast to traditional single-purpose ML models trained end-to-end for a specific science objective, FMs derive their value from serving a broad range of downstream use cases. This generality introduces new evaluation challenges: it is critical to assess performance across the full spectrum of tasks to which the FM will be applied, ensuring that it can be successfully adapted to each. In addition, because FMs are trained on large and difficult-to-characterize datasets, they include implicit biases that must be corrected for downstream scientific applications. It is therefore important to verify the correctness of adaptation and calibration procedures for each task. Establishing a common framework of benchmarks to evaluate this adaptability must be a research priority, particularly given that such validation is not standard practice for many industry-developed FMs.

\paragraph{Benchmarks}
The development or deployment of FMs within the DESC ecosystem should be accompanied by a comprehensive suite of benchmarks designed to evaluate predictive performance across a representative range of science tasks. Particular attention should be paid to robustness under survey systematics, sensitivity to biases inherited from the FM's training data, and the ability of adaptation procedures to yield well-calibrated uncertainties for each downstream application.

\paragraph{Interpretability}
Mechanistic interpretability will provide a complementary route to validation. Techniques such as attention visualization, activation clustering, or sparse dictionary learning can be adapted to determine whether internal model representations recover known astrophysical relations including the color–magnitude diagram, the fundamental plane, or the Tully–Fisher relation. Developing astronomy-specific interpretability tools would enable DESC to quantify whether FMs encode physically meaningful correlations or merely reproduce empirical correlations.

\paragraph{Distribution shift}
Evaluation under distribution shift is also essential for robustness. DESC models must maintain reliability under temporal drift across survey years, spatial variation in observing conditions, and transfer to external datasets such as \textit{Euclid} or \textit{Roman}. Dedicated stress tests should replace the assumption of \acrfull{iid} validation, using importance-weighted calibration errors and worst-group accuracy measures to reveal biases that emerge only under covariate change. These tests will be crucial for ensuring that DESC FMs remain stable as LSST transitions from early to full survey operations.

\paragraph{Long-term impact}
Finally, the deployment of large-scale models must consider sustainability and community governance. Training and fine-tuning FMs require substantial computational resources, underscoring the need for shared development, standardized documentation, and reproducible training pipelines. Strategic coordination within DESC and with external collaborations will ensure that these models serve as transparent, responsible, and scientifically verifiable assets for the next generation of cosmological analysis.

\subsection{Large Language Models \& Agentic AI}
\label{sec:llm_agentic}

\Acrfullpl{llm} have demonstrated an ability to perform cognitive tasks and knowledge work (e.g. synthesizing information, generating text, writing and explaining code) that has triggered an \acrshort{ai} revolution over the past few years. When equipped with tools, \acrshort{llm}-powered agentic systems go further: they can develop and execute code, perform exploratory data analysis, or orchestrate multi-step workflows. As of late 2025, complex tasks, especially in software engineering, can increasingly be delegated to such systems with confidence. Although integration into scientific workflows remains nascent and faces real limitations, the pace of progress and the potentially transformative implication of the ability to delegate significant fractions of the research workflow to \acrshort{ai} suggests \acrshort{desc} should plan for how best to integrate these tools and guide the evolution of practices in line with the guiding principles in \autoref{sec:exec_summary}. The goal of integrating these tools is not automation or dehumanization, but empowerment: elevating the level at which researchers engage within the scientific process, enabling them to tackle more ambitious projects while concentrating on fundamental questions, critical interpretation, and creative reasoning. \\
Below, we review capabilities and limitations, and examine potential applications for \acrshort{desc}, ranging from mature (e.g. documentation assistance) to aspirational (e.g. AI co-scientists). Overall, this subsection aims to answer the following question: what would successful integration of \acrshortpl{llm} and agentic systems within \acrshort{desc} look like?

\subsubsection{From LLMs to Agentic AI}

\paragraph{LLMs as knowledge tools}
At baseline, \acrshortpl{llm} are sophisticated systems for language and knowledge work. They process, synthesize, and generate text, though they remain subject to hallucinations (i.e.\ false statements expressed with confidence), lack of up-to-date knowledge, and limited problem-solving skills. Some of these limitations can be mitigated to be reliable production-ready systems using for instance \acrfull{rag}, a technique which allows LLMs to ground their responses in specific documentation \citep{lewis2020rag, fan2024survey}. OpenScholar \citep{asai2024openscholar}, for example, uses \acrshort{rag} over 45 million open-access papers to synthesize citation-backed responses, substantially outperforming general-purpose models while avoiding hallucinated citations. Over the last year, the proficiency of \acrshortpl{llm} at problem solving has also significantly improved with ``reasoning models'' (e.g.\ OpenAI's o1/o3, DeepSeek-R1 \citep{deepseekR1}) which allocate additional compute at inference time to perform deliberate, multi-step problem-solving (a paradigm sometimes called test-time compute scaling). These models show marked improvements on tasks requiring extended chains of reasoning. On physics specifically, TPBench \citep{chung2025tpbench} (a benchmark of original theoretical physics problems spanning undergraduate to research difficulty) finds that newer reasoning models substantially outperform earlier systems, though research-level problems remain largely unsolved. This trajectory suggests that \acrshort{llm} capabilities in scientific reasoning will continue to improve, even as fundamental limitations persist. It is important to note that \acrshortpl{llm} alone can inform and assist, but they cannot act: they process information rather than execute tasks.

\paragraph{Agentic AI: from knowledge to action}
Agentic systems represent a conceptual leap. Where \acrshortpl{llm} generate text, agents take actions: running code, calling \acrshortpl{api}, modifying files, and interacting with compute infrastructure. These capabilities make it possible to delegate complex tasks to agents much as one might delegate to a colleague. However, not all tasks are equivalent, and a useful mental model is to ask: what could one hand off to a person of varying competency? At the ``intern'' level, current agents can reliably fix small bugs, run analyses with different parameters, or write simple tests. At the ``junior'' level, they can implement well-specified features or debug failing pipelines. ``Senior''-level capabilities (architecting new systems, making design trade-offs, validating scientific methodology) remain largely out of reach. As of 2025, agentic systems handle intern-to-junior tasks on well-defined problems; senior-level judgment requires advances that have not yet materialized, though the complexity and execution horizon of these systems continues to increase. Tools such as Claude Code, Cursor, and Devin demonstrate agents completing real software engineering tasks: calling \acrshortpl{api}, executing shell commands, maintaining context across dozens of steps, recovering from errors, and iterating toward solutions. On SWE-bench \citep{jimenez2024swebench}, a benchmark of real GitHub issues from open-source Python repositories, leading agents now resolve over 70\% of issues in the human-verified subset; on the harder SWE-bench Pro \citep{aleithan2025swebenchpro}, which targets enterprise-level problems, the best systems solve roughly 25\%. 

\paragraph{Towards Scientific Agentic Systems} Beyond software engineering, agentic systems are increasingly being applied to scientific research. A first generation of agents has focused on literature search, going beyond static \acrshort{rag} systems by using tools and iterative refinement. PaperQA2 \citep{skarlinski2024paperqa2}, developed by FutureHouse, exemplifies this approach: rather than simply retrieving from a fixed index, it uses search tools to find relevant papers, traverses citation graphs to discover related work, and iteratively refines its queries based on what it finds. This agentic approach matches or exceeds PhD-level researchers on literature retrieval benchmarks. More ambitious systems extend beyond literature search to integrate data analysis and hypothesis generation. Google DeepMind's AI co-scientist \citep{gottweis2025coscientist}, a multi-agent system built on Gemini, uses a ``generate, debate, and evolve'' approach to produce novel hypotheses; it has identified drug-repurposing candidates for liver fibrosis that were validated in laboratory experiments. FutureHouse's Robin \citep{robin2025}, an open-source multi-agent system, autonomously proposed ripasudil as a treatment for dry age-related macular degeneration and validated the hypothesis through wet-lab experiments. Edison Scientific's Kosmos \citep{kosmos2025} orchestrates parallel data-analysis and literature-search agents over 12-hour runs, producing detailed scientific reports that independent evaluators found 79\% accurate. Sakana AI's AI Scientist v2 \citep{yamada2025aiscientistv2} uses agentic tree search to autonomously generate hypotheses and run experiments, and demonstrated its ability to run end-to-end machine learning research projects. This list is by no means exhaustive, and it should also be noted that these systems remain by and large proofs-of-concept, with little independent data on their usefulness and reliability for real-world complex scientific research projects. Nonetheless, these examples illustrate the interest and rapid progress in agentic systems for scientific research.

\paragraph{LLM and agentic AI in astronomy}
In astronomy specifically, domain-tuned \acrshortpl{llm} such as AstroSage-Llama-3.1-8B \citep{dehaan2025astrosage} demonstrate that compact, astronomy-specific models can match larger general-purpose systems at lower cost. In parallel, \acrshortpl{llm} are enabling large-scale knowledge synthesis: Pathfinder \citep{iyer2024pathfinder} applies semantic retrieval and citation-aware summarization across ${\sim}350{,}000$ astrophysical papers in the \acrfull{ads}, allowing users to move from keyword-centric searches to concept-level exploration. ChatGaia\footnote{\url{https://chatgpt.com/g/g-aYZOjK5zy-chatgaia}} demonstrates the potential for natural-language interfaces to complex astronomical databases: it translates user queries into \acrshort{adql} for the Gaia Archive, making ${\sim}2$ billion stellar sources accessible without requiring query-language expertise. Several agentic proofs-of-concept have also emerged. CMBAgent \citep{laverick2024mas, xu2025cmbagent} coordinates \acrshort{rag} with local code execution to run \acrshort{mcmc} pipelines for cosmological parameter estimation from \acrfull{act} data. Mephisto \citep{mephisto} iteratively refines stellar population parameters by orchestrating multi-band galaxy observations with the \acrshort{cigale} \acrshort{sed}-fitting code \citep{cigale}. Denario \citep{Denario_2025} extends this paradigm further, spanning a full research lifecycle from idea generation through data selection, modeling, and manuscript drafting. These systems remain demonstrations rather than production tools; scientific validation of their outputs is still performed manually.

As a concrete example of the state of the art, directly relevant to \acrshort{desc}, the 2025 NeurIPS Weak Lensing Uncertainty Challenge\footnote{\url{https://www.codabench.org/competitions/8934/}} (a competition to infer cosmological parameters from simulated convergence maps while quantifying uncertainty) was won by a team using the CMBAgent system \citep{CMBAGENT}, beating a team of domain experts in weak lensing and ML who placed second without AI assistance. The CMBAgent-assisted team, though not specialists in weak lensing inference, overtook the experts within weeks and held the lead through the end of the competition. This result illustrates how \acrshort{llm}-based agentic systems can accelerate scientific research and lower the barrier to complex analysis techniques.

\paragraph{Fundamental limitations}
Current \acrshortpl{llm} and agentic systems face fundamental limitations that constrain their applicability to science. As emphasized by \citet{ilievski2025aligning}, human scientific reasoning relies on abstraction, causal inference, and conceptual transfer, whereas \acrshort{ai} systems depend on statistical interpolation. This leads to what has been termed ``jagged intelligence'': systems that solve Olympiad-level problems while failing at kindergarten logic, their capabilities forming an uneven landscape rather than a coherent skill set. Hallucination (generating confident but incorrect outputs) is a fundamental problem for scientific applications. \citet{kalai2025hallucinate} provide a theoretical explanation: current training objectives and evaluation benchmarks structurally incentivize guessing over expressing uncertainty. When a model says ``I don't know,'' benchmarks penalize this the same as being wrong, so models learn to guess confidently even when uncertain. This is not a quirk to be engineered away but a consequence of how these systems are trained and evaluated. Hallucinations span a taxonomy from factual errors about well-documented knowledge to fabricated citations to arbitrary confabulations \citep{ji2023hallucination}, and they can be subtle enough to evade casual review. For science, the danger is acute: a hallucinated statistical result or misremembered prior work could propagate through analysis undetected. Beyond hallucination, these systems face limitations particularly acute for scientific discovery. They are trained on existing literature and may fail precisely where discovery happens (at the frontier where established patterns break down). They lack reliable uncertainty quantification: unlike a careful scientist who flags when they are outside their expertise, \acrshortpl{llm} produce outputs with uniform confidence regardless of whether they are interpolating within training data or extrapolating beyond it. Finally, reproducibility is difficult: outputs are stochastic, sensitive to prompt phrasing, and subject to version drift as underlying models change (challenges that conflict with science's demand for verifiable, repeatable results). For all these reasons, human oversight remains essential for any science-critical output.

\subsubsection{Potential applications for DESC}

The following sections organize potential applications by the outcomes they serve for \acrshort{desc}, rather than by the underlying technology. Each area sits at a different level of technological maturity, and the path forward differs accordingly.

\paragraph{Knowledge work and research support}
This is the most mature application area, and the one where \acrshort{desc} members can benefit immediately. Success in this area would mean that new members can query \acrshort{desc} documentation in natural language and receive accurate, sourced answers rather than navigating distributed documentation and obscure Slack channels. It would mean that literature search moves from keywords to concepts, helping researchers find relevant work faster and discover connections across subfields. Writing assistance for drafts, summaries, and documentation would be readily available, though always with human review. As summarization capabilities improve, collaboration maintenance (meeting summaries, cross-working-group communication) could also become feasible.\\
The methodology is relatively mature. For literature work, tools like OpenScholar, PaperQA2, and Pathfinder (discussed above) already enable concept-level exploration and synthesis across large scientific corpora. General-purpose \acrshortpl{llm} can summarize papers, extract key results, bridge jargon gaps across subfields, and assist with writing tasks. Domain-tuned models like AstroSage (discussed above) have shown that compact, astronomy-specific \acrshortpl{llm} can match larger general-purpose systems on astrophysical question-answering at lower cost. \acrshort{rag} techniques allow these systems to ground their responses in specific documentation, reducing hallucinations and enabling citation of sources.\\
The path forward for \acrshort{desc} involves building a \acrshort{rag} system over collaboration documentation, tutorials, and pipeline code; establishing human review guidelines for any generated content; and starting with low-stakes applications (e.g., onboarding Q\&A) before moving to higher-stakes uses. Looking further ahead, a retrieval-augmented knowledge graph that unifies documentation, code, and literature could provide a continuously evolving record of methodological provenance, making it easier to trace how analysis choices connect to the broader literature.\\
The main challenges are hallucination (confident wrong answers erode trust, so citation of sources is essential), the maintenance burden of keeping \acrshort{rag} indices current as documentation evolves, and establishing clear guidelines for how to use, review, and acknowledge generated content.

\paragraph{Natural language interaction with data}
Natural-language interfaces can dramatically reduce the barrier to accessing complex astronomical databases and archives. Success would mean that \acrshort{desc} members can query \acrshort{lsst} catalogs, simulation products, and image archives using plain language rather than specialized query languages or custom scripts. A researcher could ask ``show me all galaxies with strong tidal features in the deep drilling fields'' and retrieve relevant candidates without writing \acrshort{sql} or navigating file systems. \\
The methodology is emerging but promising. ChatGaia\footnote{\url{https://chatgpt.com/g/g-aYZOjK5zy-chatgaia}} demonstrates that conversational interfaces to catalog data are feasible: it translates natural-language queries into \acrshort{adql} for the Gaia Archive, making ${\sim}2$ billion stellar sources accessible without query-language expertise. For imaging data, AION-Search \citep{koblischke2025aionsearch} enables semantic search across 140 million galaxy images by using vision-language models to generate captions and align image embeddings with text queries, allowing researchers to search for morphological features or rare phenomena using free-form descriptions rather than predefined categories. \\
The path forward for \acrshort{desc} involves building natural-language interfaces to key data products: LSST catalogs, difference imaging outputs, and simulation archives. Such interfaces could be grounded in schema documentation and example queries to reduce hallucinated or malformed outputs. Integration into analysis notebooks would allow seamless transitions between exploratory queries and downstream analysis. \\
The main challenges are accuracy (incorrect query translations could return misleading results), coverage (not all queries map cleanly to database operations), and validation (users need ways to verify that the system understood their intent). For image search, the additional challenge is that rare phenomena (the scientifically interesting cases) are precisely where training data is sparse.

\paragraph{Software engineering acceleration}
This area spans two levels of maturity: interactive coding assistance (mature) and autonomous operation (emerging). Success would mean that \acrshort{desc} developers spend less time on routine implementation and more on design and scientific validation. Interactive tools would help members implement features, fix bugs, and write tests faster. Autonomous agents would handle low-risk maintenance tasks (updating tutorials when APIs change, generating test coverage, fixing CI failures) and open pull requests for human review. Ultimately, implementation of new analysis pipelines could be delegated to agents, with researchers specifying requirements and validation tests in natural language. \\
The methodology for interactive use is already mature. Tools such as Claude Code, Cursor, and GitHub Copilot are widely deployed and demonstrate real productivity gains on well-specified tasks. On benchmarks like SWE-bench (discussed above), leading agents now resolve over 70\% of real GitHub issues in the human-verified subset. Autonomous operation is less mature: agents can be triggered by \acrshort{ci} failures to diagnose issues and propose fixes, but reliability remains inconsistent for complex problems. \\
The path forward for \acrshort{desc} involves broader adoption of interactive coding assistants for pipeline development, along with collaboration-specific contexts that encode common patterns (e.g., \acrshort{lsst} data structures, pipeline conventions, DESC software guidelines). For autonomous agents, the prudent approach is to pilot on low-risk tasks (test generation, docstring updates) before integrating them into \acrshort{ci} workflows. \\
The main challenges are code correctness (agents can introduce subtle bugs, so review remains essential), security (generated code may have vulnerabilities), and institutional knowledge (members may not understand code they did not write). Observability is also an important point: tracking which agent and version contributed to each change enables debugging and audit.

\paragraph{Analysis support}
This area is less mature and requires validation infrastructure before deployment. Success would mean that \acrshort{ai} assistants, integrated directly into analysis notebooks, help researchers move faster through the exploratory phase of analysis: generating visualization code from natural-language requests, suggesting statistical tests, and helping iterate on plots and diagnostics. More ambitiously, such assistants could help construct null tests and systematics checks, lowering the barrier to rigorous validation. A junior researcher could more easily implement the suite of tests that an experienced analyst would know to run, making best practices more accessible across the collaboration. Beyond individual analysis, agents could proactively monitor nightly data streams and flag anomalies, generate human-readable \acrshort{qa} summaries, or diagnose pipeline failures. Human-in-the-loop frameworks, where active-learning strategies request expert input only for ambiguous cases \citep{settles2009active, christiano2017feedback}, could optimize the use of limited expert time for monitoring. \\
The methodology is nascent. While the building blocks exist (code execution, \acrshort{rag}, multimodal understanding), integrated systems for scientific analysis support are largely experimental. Projects like Jupyter AI\footnote{\url{https://jupyter-ai.readthedocs.io/}} provide infrastructure for integrating \acrshortpl{llm} directly into notebook environments, enabling conversational assistance and code generation within analysis workflows, but robust evaluation frameworks for analysis tasks remain underdeveloped. \\
The path forward for \acrshort{desc} requires building evaluation benchmarks before deployment: curated test cases where correct answers are known, so that agent outputs can be validated. Piloting on low-stakes analysis tasks (e.g., generating diagnostic plots, summarizing pipeline logs) would build experience before moving to higher-stakes applications. Most importantly, developing clear guidelines for human oversight is critical to ensuring that researchers remain accountable for scientific conclusions: \acrshort{ai} can accelerate the work, but the responsibility for validating results and interpreting their meaning must stay with humans. \\
The main challenges are automation bias (over-trusting fluent outputs that may contain subtle errors), the difficulty of validating agent reasoning on novel analyses, and the risk that diagnostics look valid but miss real issues. For science-critical workflows, the bar for reliability is high, and current systems do not yet meet it. There is also an educational tension: critically evaluating \acrshort{ai}-generated analysis requires understanding the underlying methods, yet that understanding has traditionally come from wrestling with implementation details oneself. If \acrshort{ai} removes the friction of implementation, how do junior researchers develop the judgment needed to recognize when the \acrshort{ai} is wrong? Training the next generation to use these tools effectively, without becoming dependent on them, is an open challenge. 

\paragraph{Toward an AI co-scientist}
This is the most ambitious and speculative application area. Success would mean an agent capable of PhD-student-level work: running analyses, interpreting results, drafting manuscript sections, and iterating on feedback with sufficient robustness that a PI could trust the output as they would a competent junior colleague. Such an agent might surface connections across \acrshort{desc} working groups that humans miss, generate hypotheses grounded in both literature and data patterns, or systematically explore parameter spaces or analysis choices that would be tedious for humans to cover. The measure of success is not automation but amplification: researchers would report that these tools help them think more deeply and explore more broadly, not merely execute faster. \\
The methodology remains largely aspirational. The proofs-of-concept discussed earlier (CMBAgent, Mephisto, Denario, AI co-scientist, Robin) demonstrate that end-to-end workflow orchestration is possible, but none has demonstrated PhD-student-level robustness on real scientific problems. Scientific validation of their outputs remains entirely manual. Evaluation frameworks are beginning to emerge: \citet{ye2025replicationbench} introduce ReplicationBench, an astrophysics-specific benchmark testing whether agents can faithfully reproduce published analyses; Gravity-Bench \citep{koblischke2025gravitybench} evaluates agents on physics discovery tasks, testing their ability to plan experiments and infer physical laws from simulated gravitational systems; while ScienceBoard \citep{scienceboard2025} and DiscoveryWorld \citep{discoveryworld} assess compositional scientific reasoning more broadly. \\
The path forward is necessarily incremental. \acrshort{desc} should build on the higher-maturity applications first (documentation, coding assistance, data access), developing institutional experience and trust before attempting more autonomous scientific work. \acrshort{desc}-specific evaluation benchmarks, perhaps based on reproducing known analyses or detecting injected errors, would help measure readiness. Human oversight must remain central at every stage. \\
The challenges here are the deepest. Reaching PhD-student-level robustness requires solving the fundamental limitations described earlier: agents must know when they are outside their competence, reason about physics rather than pattern-match on surface features, and produce outputs that are reproducible with full provenance. The bar for scientific discovery is extraordinarily high. A single undetected error in an analysis pipeline could propagate into published results. Whether current architectures can be made reliable enough for this level of autonomy, or whether fundamentally new approaches are needed, remains an open question.

\subsubsection{Implementation Considerations}

Beyond the application-specific concerns discussed above, three cross-cutting considerations will shape how \acrshort{desc} integrates these tools: evaluation, governance, and infrastructure.

\paragraph{Evaluation and benchmarking}
Benchmarking is essential for improving \acrshort{ai} systems, and meaningful benchmarks can only be created by domain experts who understand what correct behavior looks like. \acrshort{desc} is well-positioned to contribute here. Benchmarks for \acrshort{desc} applications should measure: (1) factual accuracy on domain literature and documentation; (2) code validity and runtime safety; (3) reproducibility under random seed variation; and (4) robustness to distribution shift and systematic differences (e.g., early vs.\ late \acrshort{lsst} years, cross-survey transfers). Existing efforts like ReplicationBench, Gravity-Bench, and ScienceBoard (discussed above) provide templates, but \acrshort{desc}-specific benchmarks (perhaps based on reproducing published analyses, detecting injected systematics, or validating pipeline outputs) would directly measure readiness for collaboration use. Creating such benchmarks is itself a scientific contribution: it encodes expert knowledge about what matters and provides a foundation for systematic improvement.

\paragraph{Governance and reproducibility}
Each automated workflow should maintain full provenance metadata: prompts, model versions, retrieved sources, generated code, and execution logs. Observability (logging all agent actions) enables debugging and audit \citep{zhou2025autonomous}. Sandboxed execution environments enforce deterministic behavior and ensure that agent-generated code runs in secure, auditable contexts. But reproducibility remains difficult: outputs are stochastic, sensitive to prompt phrasing, and subject to version drift as underlying models change. How to ensure that an analysis performed today can be replicated next year is an open problem. Attribution also lacks established norms: how should \acrshort{ai} contributions be credited in publications? These questions require collaboration-wide discussion and policy development.

\paragraph{Infrastructure and sustainability}
The physical deployment of \acrshortpl{llm} within \acrshort{desc} must respect both scale and sustainability. Larger models are expensive to run, and the cost-capability trade-off matters for a collaboration operating over \acrshort{lsst}'s decade-long baseline. Compact open-weight models, fine-tuned on domain-specific data, offer a path to balancing capability with efficiency while avoiding vendor lock-in---AstroSage exemplifies this approach. A dedicated \acrshort{rag} layer connecting \acrshort{desc} documentation, simulation archives, and survey data products could form the backbone of an agentic knowledge infrastructure. But even with efficient models, infrastructure requires ongoing maintenance: \acrshort{rag} indices must be updated as documentation evolves, prompts need revision as models change, and \acrshort{llm} \acrshortpl{api} themselves drift over time. Planning for this maintenance burden from the outset is essential.

\bigskip
\noindent \acrshortpl{llm} and agentic systems will not replace scientific judgment, but they may extend researchers' reach (handling routine tasks, surfacing relevant literature, accelerating code development) so that human effort can concentrate where it matters most. Finding the right interaction patterns between scientists and these systems remains an open challenge. \acrshort{desc} should engage now, building evaluation infrastructure and piloting lower-risk applications, to be ready as capabilities mature. The measure of success is not automation but elevation: researchers freed to focus on fundamental questions, critical interpretation, and creative reasoning.