% ------------------------------------------------------------------
% Glossary types
% ------------------------------------------------------------------

\newglossary[mlg]{methods}{mls}{mln}{AI/ML Methods}
\newglossary[clg]{challenges}{cls}{cln}{Cross-cutting Challenges}

% Macros to invoke entries in the text
\newcommand{\meth}[1]{\gls{#1}}
\newcommand{\challenge}[1]{\gls{#1}}

% ------------------------------------------------------------------
% Color code for METHOD families
% ------------------------------------------------------------------
% F1: Probabilistic & Bayesian Inference         -> aiMethBayes (Rhino - User Anchor)
% F2: Generative Modeling                        -> aiMethGen (Muted Purple)
% F3: Deep Learning Architectures                -> aiMethDeep (Muted Cyan)
% F4: Physics-Informed & Differentiable          -> aiMethPhys (Muted Green)
% F5: Representation & Discovery                 -> aiMethRepr (Muted Teal)
% F6: Data Processing & Vision                   -> aiMethVis (Steel Blue)

\definecolor{aiMethBayes}{HTML}{263654} % Rhino (User Anchor)
\definecolor{aiMethGen}{HTML}{5D4C76}   % Muted Purple
\definecolor{aiMethDeep}{HTML}{4A7A8C}  % Muted Cyan
\definecolor{aiMethPhys}{HTML}{5C7A63}  % Muted Green
\definecolor{aiMethRepr}{HTML}{3E8E7E}  % Muted Teal
\definecolor{aiMethVis}{HTML}{5B7C99}   % Steel Blue

\newcommand{\aimethbayes}[1]{\textcolor{aiMethBayes}{\textsf{#1}}}
\newcommand{\aimethgen}[1]{\textcolor{aiMethGen}{\textsf{#1}}}
\newcommand{\aimethdeep}[1]{\textcolor{aiMethDeep}{\textsf{#1}}}
\newcommand{\aimethphys}[1]{\textcolor{aiMethPhys}{\textsf{#1}}}
\newcommand{\aimethrepr}[1]{\textcolor{aiMethRepr}{\textsf{#1}}}
\newcommand{\aimethvis}[1]{\textcolor{aiMethVis}{\textsf{#1}}}

% ------------------------------------------------------------------
% Color code for CHALLENGE families (5 categories)
% ------------------------------------------------------------------
% C1: Covariate Shifts                           -> aiChCovariate
% C2: Uncertainty Quantification                 -> aiChUQ
% C3: Scalability                                -> aiChScale
% C4: Data Sparsity & Rare Events                -> aiChSparsity
% C5: Metrics & Evaluation                       -> aiChMetrics

\definecolor{aiChCovariate}{HTML}{C2814C}  % Tussock (warm orange)
\definecolor{aiChUQ}{HTML}{92402D}         % Mule Fawn (deep red-brown)
\definecolor{aiChScale}{HTML}{7D7068}      % Dark Pumice/Taupe
\definecolor{aiChSparsity}{HTML}{5D4C76}   % Muted Purple
\definecolor{aiChMetrics}{HTML}{C06C84}    % Muted Pink

\newcommand{\aichcovariate}[1]{\textcolor{aiChCovariate}{\textsf{#1}}}
\newcommand{\aichuq}[1]{\textcolor{aiChUQ}{\textsf{#1}}}
\newcommand{\aichscale}[1]{\textcolor{aiChScale}{\textsf{#1}}}
\newcommand{\aichsparsity}[1]{\textcolor{aiChSparsity}{\textsf{#1}}}
\newcommand{\aichmetrics}[1]{\textcolor{aiChMetrics}{\textsf{#1}}}

% ------------------------------------------------------------------
% METHOD ENTRIES (IDs used with \meth{...})
% ------------------------------------------------------------------

% F1: Probabilistic & Bayesian Inference

\newglossaryentry{sbi}{%
  type=methods,
  name={\aimethbayes{Simulation-based inference (SBI)}},
  text={\aimethbayes{SBI}},
  description={Implicit-likelihood Bayesian inference using forward simulations and \acrshort{nde} techniques}
}

\newglossaryentry{neural-density-estimation}{%
  type=methods,
  name={\aimethbayes{Neural density estimation (NDE)}},
  text={\aimethbayes{NDE}},
  description={Neural networks trained to approximate probability densities, often used within \acrshort{acr:sbi}}
}

\newglossaryentry{npe}{%
  type=methods,
  name={\aimethbayes{Neural posterior estimation (NPE)}},
  text={\aimethbayes{NPE}},
  description={Direct neural approximation to the posterior distribution over parameters given simulated data}
}

\newglossaryentry{hierarchical-bayes}{%
  type=methods,
  name={\aimethbayes{Bayesian hierarchical modeling}},
  text={\aimethbayes{Hierarchical Bayes}},
  description={Hierarchical probabilistic models that share information across objects or populations}
}

\newglossaryentry{variational-inference}{%
  type=methods,
  name={\aimethbayes{Variational inference (VI)}},
  text={\aimethbayes{VI}},
  description={Optimization-based approach to approximating posterior distributions}
}

\newglossaryentry{ensembles}{%
  type=methods,
  name={\aimethbayes{Deep ensembles}},
  text={\aimethbayes{Ensembles}},
  description={Collections of models combined for improved performance and \acrshort{acr:uq}}
}

\newglossaryentry{gaussian-process}{%
  type=methods,
  name={\aimethbayes{Gaussian processes}},
  text={\aimethbayes{Gaussian processes}},
  description={Non-parametric Bayesian regression and emulation for scalar or functional outputs}
}

% F2: Generative Modeling

\newglossaryentry{diffusion-model}{%
  type=methods,
  name={\aimethgen{Diffusion / score-based models}},
  text={\aimethgen{Diffusion models}},
  description={Generative models that iteratively denoise data from a noise process, often used for images and fields}
}

\newglossaryentry{normalizing-flow}{%
  type=methods,
  name={\aimethgen{Normalizing flows}},
  text={\aimethgen{Normalizing flows}},
  description={Invertible neural networks used as flexible density models in likelihoods, posteriors, or simulators}
}

\newglossaryentry{vae}{%
  type=methods,
  name={\aimethgen{Variational autoencoders (VAEs)}},
  text={\aimethgen{VAEs}},
  description={Latent-variable generative models trained via \acrshort{vi}}
}

\newglossaryentry{emulator}{%
  type=methods,
  name={\aimethgen{Emulators}},
  text={\aimethgen{Emulators}},
  description={Surrogate models (often Gaussian process- or neural network-based) that approximate expensive simulations or likelihoods}
}

\newglossaryentry{neural-surrogate}{%
  type=methods,
  name={\aimethgen{Neural surrogates}},
  text={\aimethgen{Neural surrogates}},
  description={Neural network models trained to mimic the input--output behavior of complex physical simulations}
}

% F3: Deep Learning Architectures

\newglossaryentry{cnn}{%
  type=methods,
  name={\aimethdeep{Convolutional neural networks (CNNs)}},
  text={\aimethdeep{CNNs}},
  description={Convolution-based neural networks for image-like data, widely used for classification and regression}
}

\newglossaryentry{transformer}{%
  type=methods,
  name={\aimethdeep{Transformers}},
  text={\aimethdeep{Transformers}},
  description={Attention-based neural architectures for sequences, time series, or generic sets of tokens (including vision transformers)}
}

\newglossaryentry{rnn}{%
  type=methods,
  name={\aimethdeep{Recurrent neural networks (RNNs)}},
  text={\aimethdeep{RNNs}},
  description={Sequence models (e.g.\ \acrshortpl{lstm}, \acrshortpl{gru}) for time series and light curves}
}

\newglossaryentry{gnn}{%
  type=methods,
  name={\aimethdeep{Graph neural networks (GNNs)}},
  text={\aimethdeep{GNNs}},
  description={Neural networks designed to operate on graph-structured data, such as cosmic webs or halo catalogs}
}

\newglossaryentry{deep-network}{%
  type=methods,
  name={\aimethdeep{Deep neural networks}},
  text={\aimethdeep{Deep networks}},
  description={Generic deep learning architectures not otherwise categorized}
}

% F4: Physics-Informed & Differentiable

\newglossaryentry{differentiable-programming}{%
  type=methods,
  name={\aimethphys{Differentiable programming}},
  text={\aimethphys{Differentiable programming}},
  description={Formulation of simulations and models as differentiable programs amenable to gradient-based inference}
}

\newglossaryentry{physics-informed}{%
  type=methods,
  name={\aimethphys{Physics-informed ML}},
  text={\aimethphys{Physics-informed ML}},
  description={Machine learning models that incorporate physical laws or constraints (e.g., \acrshortpl{pinn}, \acrshortpl{enn})}
}

\newglossaryentry{symbolic-regression}{%
  type=methods,
  name={\aimethphys{Symbolic regression}},
  text={\aimethphys{Symbolic regression}},
  description={Learning analytic mathematical expressions that describe data or physical relationships}
}

% F5: Representation & Discovery

\newglossaryentry{neural-compression}{%
  type=methods,
  name={\aimethrepr{Neural compression}},
  text={\aimethrepr{Neural compression}},
  description={Learned low-dimensional representations (summary statistics or latents) of complex data}
}

\newglossaryentry{self-supervised}{%
  type=methods,
  name={\aimethrepr{Self-supervised learning}},
  text={\aimethrepr{Self-supervised learning}},
  description={Learning representations from unlabeled data by solving pretext tasks (e.g., masking, contrastive learning)}
}

\newglossaryentry{som}{%
  type=methods,
  name={\aimethrepr{Self-organizing maps (SOMs)}},
  text={\aimethrepr{SOMs}},
  description={Topology-preserving maps used for exploratory analysis and domain coverage characterization}
}

\newglossaryentry{anomaly-detection}{%
  type=methods,
  name={\aimethrepr{Anomaly detection}},
  text={\aimethrepr{Anomaly detection}},
  description={Identifying rare or out-of-distribution examples in data, crucial for new physics discovery}
}

\newglossaryentry{active-learning}{%
  type=methods,
  name={\aimethrepr{Active learning}},
  text={\aimethrepr{Active learning}},
  description={Strategies that adaptively select the most informative data points for labeling or follow-up}
}

% F6: Data Processing & Vision

\newglossaryentry{instance-segmentation}{%
  type=methods,
  name={\aimethvis{Instance segmentation}},
  text={\aimethvis{Instance segmentation}},
  description={Pixel-level segmentation of individual objects, relevant for deblending crowded scenes}
}

\newglossaryentry{object-detection}{%
  type=methods,
  name={\aimethvis{Object detection}},
  text={\aimethvis{Object detection}},
  description={Identifying and localizing objects in images (e.g., \acrshort{yolo})}
}

\newglossaryentry{deblending}{%
  type=methods,
  name={\aimethvis{Deblending algorithms}},
  text={\aimethvis{Deblending}},
  description={Separating overlapping light profiles from multiple sources}
}

% ------------------------------------------------------------------
% CHALLENGE ENTRIES (IDs used with \challenge{...})
% ------------------------------------------------------------------

% C1: Covariate Shifts

\newglossaryentry{covariate-shift}{%
  type=challenges,
  name={\aichcovariate{Covariate Shifts}},
  text={\aichcovariate{Covariate shifts}},
  description={Distribution mismatches between training and target data (e.g.\ spectroscopic selection bias, sim-to-real gaps, model misspecification). Addressed in \autoref{sec4:model-misspec}, \autoref{sec4:hybrid-gen-phys}, and \autoref{sec:discovery}}
}

% C2: Uncertainty Quantification

\newglossaryentry{uq}{%
  type=challenges,
  name={\aichuq{Uncertainty Quantification}},
  text={\aichuq{UQ}},
  description={Obtaining well-calibrated posteriors and propagating uncertainties to cosmological constraints. Addressed in \autoref{sec4:Bayes}, \autoref{sec4:sbi}, and \autoref{sec4:validation}}
}

% C3: Scalability

\newglossaryentry{scalability}{%
  type=challenges,
  name={\aichscale{Scalability}},
  text={\aichscale{Scalability}},
  description={Handling LSST-scale data volumes, real-time alert processing, and high-dimensional inference. Addressed in \autoref{sec4:Bayes}, \autoref{sec4:sbi}, and \autoref{sec4:hybrid-gen-phys}}
}

% C4: Data Sparsity & Rare Events

\newglossaryentry{data-sparsity}{%
  type=challenges,
  name={\aichsparsity{Data Sparsity \& Rare Events}},
  text={\aichsparsity{Data sparsity}},
  description={Limited labeled samples, rare transients, class imbalance, and challenging edge cases like blending. Addressed in \autoref{sec:discovery}}
}

% C5: Metrics & Evaluation

\newglossaryentry{metrics}{%
  type=challenges,
  name={\aichmetrics{Metrics \& Evaluation}},
  text={\aichmetrics{Metrics}},
  description={Task-relevant metrics, validation frameworks, benchmarking, and stress tests for DESC science. Addressed in \autoref{sec4:validation} and \autoref{sec4:physics-constraints}}
}

% ------------------------------------------------------------------
% ACRONYMS (used with \acrlong{...}, \acrshort{...}, \acrfull{...}
% ------------------------------------------------------------------

\newacronym{4most}{4MOST}{4-meter Multi-Object Spectroscopic Telescope}
\newacronym{act}{ACT}{Atacama Cosmology Telescope}
\newacronym{ads}{ADS}{\acrshort{sao} Astrophysics Data System}
\newacronym{adql}{ADQL}{Astronomical Data Query Language}
\newacronym{agn}{AGN}{active galactic nuclei}
\newacronym{agnsc}{AGNSC}{\href{https://agn.science.lsst.org/}{Active Galactic Nuclei Science Collaboration}}
\newacronym{ai}{AI}{artificial intelligence}
\newacronym{alcf}{ALCF}{Argonne Leadership Computing Facility}
\newacronym{alerce}{ALeRCE}{Automatic Learning for the Rapid Classification of Events}
\newacronym{alma}{ALMA}{Atacama Large Millimeter Array}
\newacronym{ampel}{AMPEL}{Alert Management, Photometry, and Evaluation of Light curves}
\newacronym{amsc}{AmSC}{American Science Cloud}
\newacronym{anacal}{AnaCal}{Analytic Calibration}
\newacronym{antares}{ANTARES}{Arizona--NOIRLab Temporal Analysis and Response to Events System}
\newacronym{api}{API}{application programming interface}
\newacronym{ascend}{ASCEND}{A Statement of Community Engagement and Needs for Digital Research Infrastructure}
\newacronym{ascr}{ASCR}{Advanced Scientific Computing Research}
\newacronym{atat}{ATAT}{Astronomical Transformer for time series And Tabular data}
\newacronym{bliss}{BLISS}{Bayesian Light Source Separator}
\newacronym{bnn}{BNN}{Bayesian neural network}
\newacronym{camb}{CAMB}{Code for Anisotropies in the Microwave Background}
\newacronym{candels}{CANDELS}{Cosmic Assembly Near-infrared Deep Extragalactic Legacy Survey}
\newacronym{ccd}{CCD}{charge-coupled device}
\newacronym{cc-in2p3}{CC-IN2P3}{\acrshort{in2p3} Computing Centre}
\newacronym{cd}{CD}{continuous delivery/deployment}
\newacronym{ci}{CI}{continuous integration}
\newacronym{cigale}{CIGALE}{Code Investigating GALaxy Evolution}
\newacronym{clmm}{CLMM}{Cluster Lens Mass Modeling tool}
\newacronym{cmb}{CMB}{cosmic microwave background}
\newacronym{cmnn}{CMNN}{color-matched nearest-neighbors}
\newacronym{acr:cnn}{CNN}{convolutional neural network}
\newacronym{cosmodc2}{CosmoDC2}{Cosmological Data Challenge 2}
\newacronym{cpu}{CPU}{central processing unit}
\newacronym{csd3}{CSD3}{Cambridge Service for Data Driven Discovery}
\newacronym{csp}{CSP}{Carnegie Supernova Project}
\newacronym{deepdisc}{DeepDISC}{Detection, Instance Segmentation, and Classification with Deep Learning}
\newacronym{decals}{DECaLS}{Dark Energy Camera Legacy Survey}
\newacronym{des}{DES}{Dark Energy Survey}
\newacronym{desc}{DESC}{\href{https://lsstdesc.org}{Dark Energy Science Collaboration}}
\newacronym{desi}{DESI}{Dark Energy Spectroscopic Instrument}
\newacronym{dl}{DL}{deep learning}
\newacronym{dnf}{DNF}{directional neighborhood fitting}
\newacronym{doe}{DOE}{Department of Energy}
\newacronym{dsps}{DSPS}{Differentiable Stellar Population Synthesis}
\newacronym{elasticc}{ELAsTiCC}{Extended LSST Astronomical Time Series Classification Challenge}
\newacronym{ellis}{ELLIS}{European Laboratory for Learning and Intelligent Systems}
\newacronym{enn}{ENN}{equivariant neural network}
\newacronym{esa}{ESA}{European Space Agency}
\newacronym{esnet}{ESNet}{Energy Sciences Network}
\newacronym{eucaif}{EuCAIF}{European Coalition for AI for Fundamental Physics}
\newacronym{eurohpc}{EuroHPC}{European High-Performance Computing Joint Undertaking}
\newacronym{fm}{FM}{foundation model}
\newacronym{fsps}{FSPS}{Flexible Stellar Population Synthesis}
\newacronym{galsc}{GSC}{\href{https://sites.google.com/view/lsstgsc/home}{Galaxies Science Collaboration}}
\newacronym{gan}{GAN}{generative adversarial network}
\newacronym{ggns}{GGNS}{gradient-guided nested sampling}
\newacronym{acr:gnn}{GNN}{graph neural network}
\newacronym{gpz}{GPz}{Gaussian Processes for Photo-$z$}
\newacronym{gpu}{GPU}{graphics processing unit}
\newacronym{gru}{GRU}{gated recurrent unit}
\newacronym{hats}{HATS}{Hierarchical Adaptive Tiling Scheme}
\newacronym{hmc}{HMC}{Hamiltonian Monte Carlo}
\newacronym{hod}{HOD}{halo occupancy distribution}
\newacronym{hpc}{HPC}{high-performance computing}
\newacronym{hpdf}{HPDF}{High Performance Data Facility}
\newacronym{hsc}{HSC}{Hyper Suprime-Cam}
\newacronym{hst}{\textit{HST}}{\textit{Hubble Space Telescope}}
\newacronym{ia}{IA}{Intrinsic Alignment}
\newacronym{iaifi}{IAIFI}{NSF Institute for Artificial Intelligence and Fundamental Interactions}
\newacronym{idac}{IDAC}{Independent Data Access Center}
\newacronym{iid}{IID}{independent and identically distributed}
\newacronym{imnn}{IMNN}{information-maximizing neural network}
\newacronym{in2p3}{IN2P3}{Institut National de Physique Nucl\'{e}aire et de Physique des Particules}
\newacronym{ir}{IR}{infrared}
\newacronym{iri}{IRI}{Integrated Research Infrastructure}
\newacronym{issc}{ISSC}{\href{https://issc.science.lsst.org/}{Informatics and Statistics Science Collaboration}}
\newacronym{jupiter}{JUPITER}{Joint Undertaking Pioneer for Innovative and Transformative Exascale Research}
\newacronym{jwst}{\textit{JWST}}{\textit{James Webb Space Telescope}}
\newacronym{kids}{KiDS}{Kilo Degree Survey}
\newacronym{kne}{KNe}{kilonovae}
\newacronym{knn}{kNN}{$k$-nearest neighbors}
\newacronym{lccf}{LCCF}{Leadership Class Computing Facility}
\newacronym{lcdm}{$\Lambda$CDM}{cold dark matter with cosmological constant}
\newacronym{lincc}{LINCC Frameworks}{LSST Interdisciplinary Network for Collaboration and Computing Frameworks}
\newacronym{llm}{LLM}{large language model}
\newacronym{lmc}{LMC}{Langevin Monte Carlo}
\newacronym{lsst}{LSST}{Legacy Survey of Space and Time}
\newacronym{lsst-da}{LSST-DA}{LSST Discovery Alliance}
\newacronym{lstm}{LSTM}{long short-term memory}
\newacronym{lumi}{LUMI}{Large Unified Modern Infrastructure}
\newacronym{madness}{MADNESS}{Maximum A posteriori with Deep NEural networks for Source Separation}
\newacronym{map}{MAP}{maximum a posteriori}
\newacronym{mas}{MAS}{multi-agent systems}
\newacronym{mchmc}{MCHMC}{micro-canonical Hamiltonian Monte Carlo}
\newacronym{mclmc}{MCLMC}{micro-canonical Langevin Monte Carlo}
\newacronym{mcmc}{MCMC}{Markov chain Monte Carlo}
\newacronym{ml}{ML}{machine learning}
\newacronym{moc}{MOC}{multi-order coverage}
\newacronym{moe}{MoE}{mixture-of-experts}
\newacronym{mvit}{MViT}{multiscale vision transformers}
\newacronym{nasa}{NASA}{National Aeronautics and Space Administration}
\newacronym{nde}{NDE}{neural density estimation}
\newacronym{nersc}{NERSC}{National Energy Research Scientific Computing Center}
\newacronym{nfw}{NFW}{Navarro--Frenk--White}
\newacronym{nle}{NLE}{neural likeliood estimation}
\newacronym{noirlab}{NOIRLab}{National Optical-Infrared Astronomy Research Laboratory}
\newacronym{acr:npe}{NPE}{neural posterior estimation}
\newacronym{nre}{NRE}{neural ratio estimation}
\newacronym{nsf}{NSF}{National Science Foundation}
\newacronym{nuts}{NUTS}{No U-Turn Sampler}
\newacronym{ode}{ODE}{ordinary differential equation}
\newacronym{olcf}{OLCF}{Oak Ridge Leadership Computing Facility}
\newacronym{onnx}{ONNX}{Open Neural Network Exchange}
\newacronym{opsim}{OpSim}{Operations Simulator}
\newacronym{pan-starrs}{Pan-STARRS}{Panoramic Survey Telescope and Rapid Response System}
\newacronym{pdf}{PDF}{probability density function}
\newacronym{photoz}{photo-$z$}{photometric redshift}
\newacronym{pinn}{PINN}{physics-informed neural network}
\newacronym{pisn}{PISN}{pair instability supernova}
\newacronym{pit}{PIT}{probability integral transform}
\newacronym{plasticc}{PLAsTiCC}{Photometric LSST Astronomical Time Series Classification Challenge}
\newacronym{psf}{PSF}{point-spread function}
\newacronym{qa}{QA}{question answering}
\newacronym{rag}{RAG}{retrieval-augmented generation}
\newacronym{rail}{RAIL}{Redshift Assessment Infrastructure Layers}
\newacronym{rd}{R\&D}{research \& development}
\newacronym{redmapper}{RedMaPPer}{Red-sequence Matched-filter Probabilistic Percolation}
\newacronym{resnet}{ResNet}{residual network}
\newacronym{resspect}{RESSPECT}{Recommendation System for Spectroscopic followup}
\newacronym{rhmc}{RHMC}{Riemann Hamiltonian Monte Carlo}
\newacronym{acr:rnn}{RNN}{recurrent neural network}
\newacronym{rsp}{RSP}{Rubin Science Platform}
\newacronym{sao}{SAO}{Smithsonian Astrophysical Observatory}
\newacronym{sassafras}{SASSAFRAS}{S/N Analysis of Simulated SpectrA for Rubin trAnsientS}
\newacronym{acr:sbi}{SBI}{simulation-based inference}
\newacronym{sbm}{SBM}{score-based model}
\newacronym{sde}{SDE}{stochastic differential equation}
\newacronym{sdss}{SDSS}{Sloan Digital Sky Survey}
\newacronym{sed}{SED}{spectral energy distribution}
\newacronym{sfh}{SFH}{star formation history}
\newacronym{sfr}{SFR}{star formation rate}
\newacronym{ssfr}{sSFR}{specific star formation rate}
\newacronym{skai}{SkAI}{NSF--Simons AI Institute for the Sky}
\newacronym{slac}{SLAC}{Stanford Linear Accelerator Center}
\newacronym{slacs}{SLACS}{Sloan Lens ACS (Advanced Camera for Surveys) Survey}
\newacronym{slsc}{SLSC}{\href{https://sites.google.com/view/lsst-stronglensing}{Strong Lensing Science Collaboration}}
\newacronym{smwlv}{SMWLVSC}{\href{https://rubin-smwlv.github.io/}{Stars, Milky Way, and Local Volume Science Collaboration}}
\newacronym{snana}{SNANA}{Supernova Analysis package}
\newacronym{sne}{SNe}{supernovae}
\newacronym{snia}{SN Ia}{Type Ia supernova}
\newacronym{snr}{SNR}{signal-to-noise ratio}
\newacronym{so}{SO}{Simons Observatory}
\newacronym{soar}{SOAR}{Southern Astrophysical Research Telescope}
\newacronym{acr:som}{SOM}{self-organizing map}
\newacronym{spherex}{\textit{SPHEREx}}{\textit{Spectro-Photometer for the History of the Universe, Epoch of Reionization, and Ices Explorer}}
\newacronym{sps}{SPS}{stellar population synthesis}
\newacronym{spt}{SPT}{South Pole Telescope}
\newacronym{ssl}{SSL}{self-supervised Learning}
\newacronym{sql}{SQL}{structured query language}
\newacronym{sssc}{SSSC}{\href{https://lsst-sssc.github.io}{Solar System Science Collaboration}}
\newacronym{stratlearn}{StratLearn}{stratified learning}
\newacronym{svm}{SVM}{support vector machine}
\newacronym{sz}{SZ}{Sunyaev--Zeldovich}
\newacronym{tides}{TiDES}{Time Domain Extragalactic Survey}
\newacronym{tpz}{TPZ}{Trees for Photo-$z$}
\newacronym{tvs}{TVSSC}{\href{https://lsst-tvssc.github.io/}{Transients and Variable Stars Science Collaboration}}
\newacronym{acr:uq}{UQ}{uncertainty quantification}
\newacronym{usdf}{USDF}{US Data Facility}
\newacronym{uv}{UV}{ultraviolet}
\newacronym{acr:vae}{VAE}{variational autoencoder}
\newacronym{vi}{VI}{variational inference}
\newacronym{wazp}{WaZP}{Wavelet Z-Photometric}
\newacronym{wcdm}{$w$CDM}{cold dark matter with cosmological equation of state}
\newacronym{wg}{WG}{working group}
\newacronym{wise}{\textit{WISE}}{\textit{Wide-field Infrared Survey Explorer}}
\newacronym{yolo}{YOLO}{You Only Look Once}
\newacronym{ztf}{ZTF}{Zwicky Transient Facility}
